{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8943aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda import amp\n",
    "from spikingjelly.clock_driven import functional, surrogate, layer, neuron\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca2425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "_seed_ = 2020\n",
    "torch.manual_seed(_seed_)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(_seed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258f8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingLayer(nn.Module):\n",
    "    def __init__(self, voter_num: int):\n",
    "        super().__init__()\n",
    "        self.voting = nn.AvgPool1d(voter_num, voter_num)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.voting(x.unsqueeze(1)).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eaa29f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PythonNet(nn.Module):\n",
    "    def __init__(self, channels: int):\n",
    "        super().__init__()\n",
    "        conv = []\n",
    "        conv.extend(PythonNet.conv3x3(2, channels))\n",
    "        conv.append(nn.MaxPool2d(2, 2))\n",
    "        \n",
    "        for i in range(4):\n",
    "            conv.extend(PythonNet.conv3x3(channels, channels))\n",
    "            conv.append(nn.MaxPool2d(2, 2))\n",
    "        \n",
    "        self.conv = nn.Sequential(*conv)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            layer.Dropout(0.5),\n",
    "            nn.Linear(channels * 4 * 4, channels * 2 * 2, bias=False),\n",
    "            neuron.LIFNode(tau=2.0, surrogate_function=surrogate.ATan(), detach_reset=True),\n",
    "            layer.Dropout(0.5),\n",
    "            nn.Linear(channels * 2 * 2, 110, bias=False),\n",
    "            neuron.LIFNode(tau=2.0, surrogate_function=surrogate.ATan(), detach_reset=True)\n",
    "        )\n",
    "        \n",
    "        self.vote = VotingLayer(10)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x.permute(1, 0, 2, 3, 4)\n",
    "        out_spikes = self.vote(self.fc(self.conv(x[0])))\n",
    "        for t in range(1, x.shape[0]):\n",
    "            out_spikes += self.vote(self.fc(self.conv(x[t])))\n",
    "        return out_spikes / x.shape[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def conv3x3(in_channels: int, out_channels):\n",
    "        return [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            neuron.LIFNode(tau=2.0, surrogate_function=surrogate.ATan(), detach_reset=True)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "288a2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Custom pytorch Dataset class for event raw data\n",
    "'''\n",
    "import os\n",
    "class DVSDATASET(Dataset):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b689cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''\n",
    "    .. code:: bash\n",
    "        usage: gesture-model.py [-h] [-T T] [-device DEVICE] [-b B] [-epochs N] [-j N] [-channels CHANNELS] [-data_dir DATA_DIR] [-out_dir OUT_DIR] [-resume RESUME] [-amp] [-cupy] [-opt OPT] [-lr LR] [-momentum MOMENTUM] [-lr_scheduler LR_SCHEDULER] [-step_size STEP_SIZE] [-gamma GAMMA] [-T_max T_MAX]\n",
    "        Classify DVS128 Gesture\n",
    "        optional arguments:\n",
    "          -data_dir DATA_DIR    root dir of DVS128 Gesture dataset\n",
    "          -out_dir OUT_DIR      root dir for saving logs and checkpoint\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser(description='Classify DVS128 Gesture')\n",
    "    parser.add_argument('-data_dir', type=str, help='root dir of DVS128 Gesture dataset')\n",
    "    parser.add_argument('-out_dir', type=str, help='root dir for saving logs and checkpoint')\n",
    "\n",
    "    args = parser.parse_args(['-data_dir', './dataset', '-out_dir', './logs'])\n",
    "    print(args)\n",
    "    \n",
    "    net = PythonNet(channels=128)\n",
    "    print(net)\n",
    "    net.to('cuda:0')\n",
    "\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=32)\n",
    "\n",
    "    \n",
    "    train_set = DVS128Gesture(args.data_dir, train=True, data_type='event', split_by='number', frames_number=16)\n",
    "    test_set = DVS128Gesture(args.data_dir, train=False, data_type='event', split_by='number', frames_number=16)\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        drop_last=True,\n",
    "        pin_memory=True)\n",
    "\n",
    "    test_data_loader = DataLoader(\n",
    "        dataset=test_set,\n",
    "        batch_size=16,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        drop_last=False,\n",
    "        pin_memory=True)\n",
    "\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    start_epoch = 0\n",
    "    max_test_acc = 0\n",
    "    \n",
    "    out_dir = os.path.join(args.out_dir, f'T_{16}_b_{16}_c_{128}_SGD_lr_{0.001}_CosALR_{32}_amp')\n",
    "    \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "        print(f'Mkdir {out_dir}.')\n",
    "        \n",
    "    writer = SummaryWriter(os.path.join(out_dir, 'dvsg_logs'), purge_step=start_epoch)\n",
    "    \n",
    "    for epoch in range(start_epoch, 64):\n",
    "        start_time = time.time()\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_samples = 0\n",
    "        for frame, label in train_data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            frame = frame.float().to('cuda:0')\n",
    "            label = label.to('cuda:0')\n",
    "            label_onehot = F.one_hot(label, 11).float()\n",
    "            \n",
    "            with amp.autocast():\n",
    "                out_fr = net(frame)\n",
    "                loss = F.mse_loss(out_fr, label_onehot)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_samples += label.numel()\n",
    "            train_loss += loss.item() * label.numel()\n",
    "            train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "            functional.reset_net(net)\n",
    "            \n",
    "        train_loss /= train_samples\n",
    "        train_acc /= train_samples\n",
    "\n",
    "        writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('train_acc', train_acc, epoch)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        test_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for frame, label in test_data_loader:\n",
    "                frame = frame.float().to('cuda:0')\n",
    "                label = label.to('cuda:0')\n",
    "                label_onehot = F.one_hot(label, 11).float()\n",
    "                out_fr = net(frame)\n",
    "                loss = F.mse_loss(out_fr, label_onehot)\n",
    "\n",
    "                test_samples += label.numel()\n",
    "                test_loss += loss.item() * label.numel()\n",
    "                test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "                functional.reset_net(net)\n",
    "\n",
    "        test_loss /= test_samples\n",
    "        test_acc /= test_samples\n",
    "\n",
    "        writer.add_scalar('test_loss', test_loss, epoch)\n",
    "        writer.add_scalar('test_acc', test_acc, epoch)\n",
    "        \n",
    "        save_max = False\n",
    "        if test_acc > max_test_acc:\n",
    "            max_test_acc = test_acc\n",
    "            save_max = True\n",
    "\n",
    "        checkpoint = {\n",
    "            'net': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'max_test_acc': max_test_acc\n",
    "        }\n",
    "        \n",
    "        if save_max:\n",
    "            torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_max.pth'))\n",
    "        \n",
    "        torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_max.pth'))\n",
    "\n",
    "        print(f'epoch={epoch}, train_loss={train_loss}, train_acc={train_acc}, test_loss={test_loss}, test_acc={test_acc}, max_test_acc={max_test_acc}, total_time={time.time() - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ad47a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(data_dir='./dataset', out_dir='./logs')\n",
      "PythonNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(2, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=True, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=True, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=True, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=True, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=True, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Dropout(p=0.5)\n",
      "    (2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "    (3): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=True, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (4): Dropout(p=0.5)\n",
      "    (5): Linear(in_features=512, out_features=110, bias=False)\n",
      "    (6): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=True, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "  )\n",
      "  (vote): VotingLayer(\n",
      "    (voting): AvgPool1d(kernel_size=(10,), stride=(10,), padding=(0,))\n",
      "  )\n",
      ")\n",
      "Mkdir [./dataset\\download] to save downloaded files.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "This dataset can not be downloaded by SpikingJelly, please download files manually and put files at [./dataset\\download]. The resources file_name, url, and md5 are: \n[('DvsGesture.tar.gz', 'https://ibm.ent.box.com/s/3hiq58ww1pbbjrinh367ykfdf60xsfm8/folder/50167556794', '8a5c71fb11e24e5ca5b11866ca6c00a1'), ('gesture_mapping.csv', 'https://ibm.ent.box.com/s/3hiq58ww1pbbjrinh367ykfdf60xsfm8/folder/50167556794', '109b2ae64a0e1f3ef535b18ad7367fd1'), ('LICENSE.txt', 'https://ibm.ent.box.com/s/3hiq58ww1pbbjrinh367ykfdf60xsfm8/folder/50167556794', '065e10099753156f18f51941e6e44b66'), ('README.txt', 'https://ibm.ent.box.com/s/3hiq58ww1pbbjrinh367ykfdf60xsfm8/folder/50167556794', 'a0663d3b1d8307c329a43d949ee32d19')]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11772/217905245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11772/2622044502.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDVS128Gesture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'event'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_by\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'number'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes_number\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDVS128Gesture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'event'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_by\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'number'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes_number\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\spikingjelly\\datasets\\dvs128_gesture.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, data_type, frames_number, split_by, duration, transform, target_transform)\u001b[0m\n\u001b[0;32m     54\u001b[0m         '''\n\u001b[0;32m     55\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_by\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mresource_url_md5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\spikingjelly\\datasets\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, data_type, frames_number, split_by, duration, transform, target_transform)\u001b[0m\n\u001b[0;32m    636\u001b[0m                         \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m                     raise NotImplementedError(f'This dataset can not be downloaded by SpikingJelly, '\n\u001b[0m\u001b[0;32m    639\u001b[0m                                               \u001b[1;34mf'please download files manually and put files at [{download_root}]. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m                                               f'The resources file_name, url, and md5 are: \\n{resource_list}')\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: This dataset can not be downloaded by SpikingJelly, please download files manually and put files at [./dataset\\download]. The resources file_name, url, and md5 are: \n[('DvsGesture.tar.gz', 'https://ibm.ent.box.com/s/3hiq58ww1pbbjrinh367ykfdf60xsfm8/folder/50167556794', '8a5c71fb11e24e5ca5b11866ca6c00a1'), ('gesture_mapping.csv', 'https://ibm.ent.box.com/s/3hiq58ww1pbbjrinh367ykfdf60xsfm8/folder/50167556794', '109b2ae64a0e1f3ef535b18ad7367fd1'), ('LICENSE.txt', 'https://ibm.ent.box.com/s/3hiq58ww1pbbjrinh367ykfdf60xsfm8/folder/50167556794', '065e10099753156f18f51941e6e44b66'), ('README.txt', 'https://ibm.ent.box.com/s/3hiq58ww1pbbjrinh367ykfdf60xsfm8/folder/50167556794', 'a0663d3b1d8307c329a43d949ee32d19')]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
